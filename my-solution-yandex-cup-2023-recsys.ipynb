{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6787298,"sourceType":"datasetVersion","datasetId":3904467}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Yandex Cup 2023 RecSys\n\nОдной из ключевых прикладных задач сервиса Яндекс Музыка является автоматическое распознавание жанров музыки. Автоматическая разметка треков по жанрам позволяет более точно подбирать рекомендации с помощью такой фичи, как \"Моя волна\", адаптирующейся под настроение и музыкальные вкусы пользователей. Так, например, любителям heavy metal не стоит предлагать послушать поп-музыку, а любителям классики - рэп. \n\nТак как количество музыкальных треков в сервисе Яндекс Музыка достаточно велико, то ручная разметка каждого трека малоэффективна, и возникает потребность в разработке модели, выполняющей разметку треков для рекомендательной системы \"Моя волна\" автоматически. Более того, не для всех треков имеется хорошая разметка, и хотелось бы знать не только верхнеуровневый жанр (например, рок), так и микрожанр (например, heavy metal).\n\nТаким образом, **целью проекта** является разработка multi-labeled классификатора треков на основе их эмбеддингов, полученных с помощью автоэнкодера.","metadata":{}},{"cell_type":"markdown","source":"## Импорт библиотек\n\nВ ходе работы были использованы следующие библиотеки:\n- ***Pandas*** - для чтения csv файлов, содержащих разметку треков по жанрам для обучающих данных и номера треков из тестовой выборки, для которых необходимо выполнить предсказание жанра.\n- ***Numpy*** - для чтения файлов .npy, содержащих эмбеддинги треков\n- ***PyTorch*** - фреймворк для обучения нейронных сетей.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom datetime import datetime\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics.classification import AveragePrecision\nfrom sklearn.model_selection import train_test_split\nimport os\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-07T13:59:38.926270Z","iopub.execute_input":"2023-12-07T13:59:38.926619Z","iopub.status.idle":"2023-12-07T13:59:53.669902Z","shell.execute_reply.started":"2023-12-07T13:59:38.926589Z","shell.execute_reply":"2023-12-07T13:59:53.669025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Настраиваем torch и запишем основные константы\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nNUM_TAGS = 256 \nPATH = '/kaggle/input/yandex-cup-2023-recsys/'","metadata":{"execution":{"iopub.status.busy":"2023-12-07T14:00:11.710659Z","iopub.execute_input":"2023-12-07T14:00:11.711017Z","iopub.status.idle":"2023-12-07T14:00:11.747787Z","shell.execute_reply.started":"2023-12-07T14:00:11.710989Z","shell.execute_reply":"2023-12-07T14:00:11.746567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Загрузка данных.\n\nДанные для обучения и тестовые треки хранятся в файлах train.csv и test.csv, а также в каталоге track_embeddings. Загрузим их и создадим загрузчики для их подачи на вход модели.","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(PATH + 'train.csv')\ndf_test = pd.read_csv(PATH + 'test.csv')\ndf_train, df_val = train_test_split(df_train, test_size=0.2, random_state=777)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T14:00:16.088348Z","iopub.execute_input":"2023-12-07T14:00:16.089248Z","iopub.status.idle":"2023-12-07T14:00:16.165537Z","shell.execute_reply.started":"2023-12-07T14:00:16.089203Z","shell.execute_reply":"2023-12-07T14:00:16.164543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"track_idx2embeds = {}\nfor fn in tqdm(os.listdir(PATH + 'track_embeddings')):\n    track_idx = int(fn[:-4])\n    embeds = torch.from_numpy(np.load(PATH + 'track_embeddings/' + fn))\n    track_idx2embeds[track_idx] = embeds","metadata":{"execution":{"iopub.status.busy":"2023-12-07T14:00:18.401182Z","iopub.execute_input":"2023-12-07T14:00:18.401831Z","iopub.status.idle":"2023-12-07T14:06:33.044166Z","shell.execute_reply.started":"2023-12-07T14:00:18.401796Z","shell.execute_reply":"2023-12-07T14:06:33.043179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TaggingDataset(Dataset):\n    def __init__(self, df, testing=False):\n        self.df = df\n        self.testing = testing\n        \n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        track_idx = row.track\n        embeds = track_idx2embeds[track_idx]\n        if self.testing:\n            return track_idx, embeds\n        tags = [int(x) for x in row.tags.split(',')]\n        target = torch.zeros(NUM_TAGS)\n        target[tags] = 1\n        return track_idx, embeds, target","metadata":{"execution":{"iopub.status.busy":"2023-12-07T14:41:28.801147Z","iopub.execute_input":"2023-12-07T14:41:28.801897Z","iopub.status.idle":"2023-12-07T14:41:28.808938Z","shell.execute_reply.started":"2023-12-07T14:41:28.801866Z","shell.execute_reply":"2023-12-07T14:41:28.807914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = TaggingDataset(df_train)\nval_dataset = TaggingDataset(df_val)\ntest_dataset = TaggingDataset(df_test, True)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T14:41:29.298473Z","iopub.execute_input":"2023-12-07T14:41:29.299545Z","iopub.status.idle":"2023-12-07T14:41:29.303831Z","shell.execute_reply.started":"2023-12-07T14:41:29.299512Z","shell.execute_reply":"2023-12-07T14:41:29.302857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collate_fn(b):\n    track_idxs = torch.from_numpy(np.vstack([x[0] for x in b]))\n    embeds = nn.utils.rnn.pad_sequence([x[1] for x in b], batch_first=True)\n    targets = np.vstack([x[2] for x in b])\n    targets = torch.from_numpy(targets)\n    embeds = embeds + torch.empty(embeds.shape).normal_(mean=0.00, std=0.05)\n    return track_idxs, embeds, targets\n\ndef collate_fn_val(b):\n    track_idxs = torch.from_numpy(np.vstack([x[0] for x in b]))\n    embeds = nn.utils.rnn.pad_sequence([x[1] for x in b], batch_first=True)\n    targets = np.vstack([x[2] for x in b])\n    targets = torch.from_numpy(targets)\n    return track_idxs, embeds, targets\n\ndef collate_fn_test(b):\n    track_idxs = torch.from_numpy(np.vstack([x[0] for x in b]))\n    embeds = nn.utils.rnn.pad_sequence([x[1] for x in b], batch_first=True)\n    return track_idxs, embeds","metadata":{"execution":{"iopub.status.busy":"2023-12-07T14:41:39.412291Z","iopub.execute_input":"2023-12-07T14:41:39.413301Z","iopub.status.idle":"2023-12-07T14:41:39.422672Z","shell.execute_reply.started":"2023-12-07T14:41:39.413266Z","shell.execute_reply":"2023-12-07T14:41:39.421637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\nval_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn_val)\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T14:41:40.044780Z","iopub.execute_input":"2023-12-07T14:41:40.045455Z","iopub.status.idle":"2023-12-07T14:41:40.051190Z","shell.execute_reply.started":"2023-12-07T14:41:40.045425Z","shell.execute_reply":"2023-12-07T14:41:40.049946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучение модели\n\nДля предсказания жанра треков была использована нейронная сеть, сочетающая кодировщик трансформера и блоки сверточных слоев. Выводы кодировщика поступают на вход четырех одномерных сверточных блоков с различным размером окна для улавливания паттернов, характерных для того или иного жанра. Выводы сверточных блоков классифицируются при помощи многослойного перцептрона.","metadata":{}},{"cell_type":"code","source":"class Network(nn.Module):\n    def __init__(\n        self,\n        num_classes = NUM_TAGS\n    ):\n        super().__init__() \n        \n        # Блок кодировщика\n        self.encoder_layer = nn.TransformerEncoderLayer(d_model=768, \n                                                        nhead=4,\n                                                        activation='relu',\n                                                        batch_first=True,\n                                                        dim_feedforward=2048\n                                                       )\n        self.encoder = nn.TransformerEncoder(self.encoder_layer,\n                                             num_layers=1\n                                            )\n        \n        # Сверточные блоки\n        self.conv7 = nn.Sequential(\n            nn.Conv1d(768, 768, kernel_size=7, padding='same'),\n            nn.ReLU(),\n            nn.Conv1d(768, 768, kernel_size=5, padding='same'),\n            nn.ReLU(),\n            nn.Conv1d(768, 768, kernel_size=5, padding='same'),\n            nn.ReLU()\n        )\n        self.conv5 = nn.Sequential(\n            nn.Conv1d(768, 768, kernel_size=5, padding='same'),\n            nn.ReLU(),\n            nn.Conv1d(768, 768, kernel_size=3, padding='same'),\n            nn.ReLU(),\n            nn.Conv1d(768, 768, kernel_size=3, padding='same'),\n            nn.ReLU()\n        )\n        self.conv3 = nn.Sequential(\n            nn.Conv1d(768, 768, kernel_size=3, padding='same'),\n            nn.ReLU(),\n            nn.Conv1d(768, 768, kernel_size=3, padding='same'),\n            nn.ReLU(),\n            nn.Conv1d(768, 768, kernel_size=3, padding='same'),\n            nn.ReLU()\n        )\n        self.conv1 = nn.Sequential(\n            nn.Conv1d(768, 768, kernel_size=1, padding='same'),\n            nn.ReLU()\n        )\n        # Многослойный перцептрон\n        self.lin = nn.Sequential(\n            nn.Dropout1d(),\n            nn.Linear(3072, 768),\n            nn.ReLU(),\n            nn.BatchNorm1d(768),\n            nn.Linear(768, 768),\n            nn.ReLU(),\n            nn.BatchNorm1d(768),\n            nn.Linear(768, num_classes)\n        )\n                                  \n    def forward(self, embeds):\n        x = self.encoder(embeds)\n        x = torch.permute(x, (0, 2, 1))\n        c1, _ = torch.max(self.conv7(x), dim=2)\n        c2, _ = torch.max(self.conv5(x), dim=2)\n        c3, _ = torch.max(self.conv3(x), dim=2)\n        c4, _ = torch.max(self.conv1(x), dim=2)\n        x = torch.cat([c1, c2, c3, c4], dim=1)\n        x = self.lin(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T14:10:10.212150Z","iopub.execute_input":"2023-12-07T14:10:10.212812Z","iopub.status.idle":"2023-12-07T14:10:10.227454Z","shell.execute_reply.started":"2023-12-07T14:10:10.212780Z","shell.execute_reply":"2023-12-07T14:10:10.226537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, loader):\n    model.eval()\n    track_idxs = []\n    predictions = []\n    with torch.no_grad():\n        for data in loader:\n            track_idx, embeds = data\n            embeds = embeds.to(device)\n            pred_logits = model(embeds)\n            pred_probs = torch.sigmoid(pred_logits)\n            predictions.append(pred_probs.cpu().numpy())\n            track_idxs.append(track_idx.numpy())\n    predictions = np.vstack(predictions)\n    track_idxs = np.vstack(track_idxs).ravel()\n    return track_idxs, predictions\n            ","metadata":{"execution":{"iopub.status.busy":"2023-12-07T14:06:40.467318Z","iopub.execute_input":"2023-12-07T14:06:40.468146Z","iopub.status.idle":"2023-12-07T14:06:40.474327Z","shell.execute_reply.started":"2023-12-07T14:06:40.468113Z","shell.execute_reply":"2023-12-07T14:06:40.473418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, val_loader):\n    model.eval()\n    metric = MultilabelAveragePrecision(NUM_TAGS, average=\"macro\", thresholds=None,)\n    with torch.no_grad():\n        for data in iter(val_loader):\n            track_idx, embeds, target = data\n            embeds = embeds.to(device)\n            target = target.int()\n            target = target.to(device)\n            pred_logits = torch.sigmoid(model(embeds))\n            metric(pred_logits, target)\n    print(f'---Validation AP: {metric.compute()}---')","metadata":{"execution":{"iopub.status.busy":"2023-12-07T14:40:49.831892Z","iopub.execute_input":"2023-12-07T14:40:49.832673Z","iopub.status.idle":"2023-12-07T14:40:49.838781Z","shell.execute_reply.started":"2023-12-07T14:40:49.832641Z","shell.execute_reply":"2023-12-07T14:40:49.837799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, loader, val_loader, criterion, optimizer, microbatches=1):\n    model.train()\n    running_loss = 0\n    optimizer.zero_grad()\n    for iteration,data in enumerate(loader):\n        torch.cuda.empty_cache()\n        track_idxs, embeds, target = data\n        embeds = embeds.to(device)\n        target = target.to(device)\n        pred_logits = model(embeds)\n        pred_probs = torch.sigmoid(pred_logits)\n        ce_loss = criterion(pred_logits, target)\n        ce_loss.backward()\n        running_loss += ce_loss.item() / microbatches\n        if (iteration + 1) % microbatches == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n            if (iteration + 1) % (microbatches*10) == 0:\n                print('   {} batch {} loss {}'.format(\n                    datetime.now(), iteration+1, running_loss\n                ))\n            running_loss = 0\n    evaluate_model(model, val_loader)\n            ","metadata":{"execution":{"iopub.status.busy":"2023-12-07T14:06:48.993101Z","iopub.execute_input":"2023-12-07T14:06:48.993842Z","iopub.status.idle":"2023-12-07T14:06:49.001682Z","shell.execute_reply.started":"2023-12-07T14:06:48.993807Z","shell.execute_reply":"2023-12-07T14:06:49.000701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Чистим RAM от всякого хлама\ntorch.cuda.empty_cache()\ngc.collect()\n\nmodel = Network()\ncriterion = nn.BCEWithLogitsLoss()\n\nepochs = 10\nmodel = model.to(device)\ncriterion = criterion.to(device)\nlr = 1e-4\noptimizer = torch.optim.AdamW(model.parameters(), lr=lr)\nfor epoch in tqdm(range(epochs)):\n    print(f'lr={lr}')\n    train_epoch(model, train_dataloader, val_dataloader, criterion, optimizer, 10)\n    lr *= 0.97\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T16:16:43.002332Z","iopub.execute_input":"2023-12-07T16:16:43.003078Z","iopub.status.idle":"2023-12-07T17:03:16.171387Z","shell.execute_reply.started":"2023-12-07T16:16:43.003045Z","shell.execute_reply":"2023-12-07T17:03:16.170423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#torch.save(model, 'transformer_cnn.pt')","metadata":{"execution":{"iopub.status.busy":"2023-12-07T17:14:15.702940Z","iopub.execute_input":"2023-12-07T17:14:15.703670Z","iopub.status.idle":"2023-12-07T17:14:16.031818Z","shell.execute_reply.started":"2023-12-07T17:14:15.703635Z","shell.execute_reply":"2023-12-07T17:14:16.030812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission\n\nЗагрузим предсказания модели на тестовой выборке и выгрузим полученный файл predictions.csv","metadata":{}},{"cell_type":"code","source":"track_idx, predictions = predict(model, test_dataloader)\npredictions_df = pd.DataFrame([\n    {'track': track, 'prediction': ','.join([str(p) for p in probs])}\n    for track, probs in zip(track_idxs, predictions)\n])","metadata":{"execution":{"iopub.status.busy":"2023-11-12T11:01:51.436759Z","iopub.execute_input":"2023-11-12T11:01:51.437047Z","iopub.status.idle":"2023-11-12T11:01:56.297784Z","shell.execute_reply.started":"2023-11-12T11:01:51.437022Z","shell.execute_reply":"2023-11-12T11:01:56.296977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_df.to_csv('prediction.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T11:01:56.298909Z","iopub.execute_input":"2023-11-12T11:01:56.299194Z","iopub.status.idle":"2023-11-12T11:01:59.842223Z","shell.execute_reply.started":"2023-11-12T11:01:56.299169Z","shell.execute_reply":"2023-11-12T11:01:59.841413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Вывод\n\nВ результате проекта была разработана модель на основе гибридной архитектуры Transformer + CNN для автоматического определения музыкальных жанров на основе эмбеддингов музыкальных треков. Средняя точность определения жанра (Average Precision) на валидационной выборке составляет 19 %.","metadata":{}}]}